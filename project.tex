\documentclass[12pt,abstracton]{scrartcl}
%packages
\usepackage{bbm}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{latexsym}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{texdraw}
\usepackage{euscript}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{mathrsfs}
\usepackage{textcomp}
\usepackage{color}
\usepackage{fancyvrb}
\usepackage{pstricks,pst-node,pst-tree}
\usepackage{subfig}
\usepackage{tikz}
\usepackage{url}
\usepackage{array}
%margins
\setlength{\textwidth}{6.5in} \setlength{\evensidemargin}{0in}
\setlength{\oddsidemargin}{0in}
\setlength{\textheight}{9in}
%section start markers
\newcommand{\lem}{\paragraph*{Lemma:}}
\newcommand{\cor}{\paragraph*{Corollary:}}
\newcommand{\prb}[1]{\section*{Problem {\text{#1}:}}}
\newcommand{\sprb}[1]{\subsection*{Item {\text{#1}:}}}
%abbreviations
\newcommand{\fa}{\forall}
\newcommand{\EE}{\exists}
\newcommand{\ee}{\epsilon}
\newcommand{\dd}{\delta}
\newcommand{\rr}{\mathbb{R}}
\newcommand{\rrx}{\rr^{\times}}
\newcommand{\qq}{\mathbb{Q}}
\newcommand{\nn}{\mathbb{N}}
\newcommand{\zz}{\mathbb{Z}}
\newcommand{\cc}{\mathbb{C}}
\newcommand{\ccx}{\cc^{\times}}
\newcommand{\oo}{\mathbb{O}}
\newcommand{\hh}{\mathbb{H}}
\newcommand{\pp}{\mathbb{P}}
\newcommand{\prm}[1]{#1^{\prime}}
\newcommand{\Letf}[3]{Let \({#1}:{#2}\rightarrow{#3}\) be}
\newcommand{\pard}[2]{\frac{\partial {#1}}{\partial {#2}}}
\newcommand{\FIT}{First Isomorphism Theorem}
\newcommand{\img}{\mathrm{img}\ }
\newcommand{\eq}[1]{\begin{equation}#1\end{equation}}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\ip}[2]{\langle{#1},{#2}\rangle}
\newcommand{\contra}{\Rightarrow\Leftarrow}
\newtheorem{thm}{Theorem}
\newtheorem{clm}{Claim}
%section end markers
\newcommand{\Qed}{\hfill$\square$\newline\newline}
\newcommand{\QED}{\hfill$\square$}
%\renewcommand*\arraystretch{1.1}
\renewcommand*{\thefootnote}{\arabic{footnote}}

\title{Code Like a Pro:\\Observations on Expert ML Code}
\subtitle{Comp150FP Final Project\footnote{This project, advised by Prof. Norman Ramsey, is also submitted in partial fulfillment of the requirements for M.S. in computer science}}
\author{Zhe Lu}
\date{10 December 2013}

\begin{document}
\bibliographystyle{alpha}
\input{epsf.sty}
\maketitle
\begin{abstract}
Beginners can become experts through directed practice towards a goal. In an effort to
help them direct their practice, we make observations about what good ML code looks like.
The aim of this paper is two-fold: (1)~identify features common to code written in Standard ML by experts and
(2)~provide suggestions to help beginners model their code after expert code.
\end{abstract}
\section{INTRODUCTION}
There are many ways to define what an expert is.
For example, an often cited rule is that one requires 10000 hours of deliberate practice
in a particular field to become an expert \cite{Gla08}. But if we want to provide novice programmers
with specifics during these 10000 hours, what should we tell them? One challenge is that experts themselves
do not necessarily know what features identify them as experts and what features are unique to them as individuals.

We attempt to shed light onto this problem by employing software metrics,
by trying to find measureable quantities
that provide some metric for evaluating software. Specifically,
We approach this problem by examining source code written by experts.

For samples of expert code, we turned to prominent projects where the source code is readily available:
\begin{enumerate}
\item The Standard ML of New Jersey compiler (SML/NJ), whose parser was used extensively for code analysis in this project (311 parseable files, 81124 lines of code)\footnote{\url{http://smlnj.cs.uchicago.edu/dist/working/110.76/compiler.tgz}}
\item The MLKit compiler for SML (2292 parseable files, totalling 530334 lines of code)\footnote{\url{http://www.itu.dk/research/mlkit/dist/mlkit-4.3.0-src.tgz}}
\item FoxNet, an implementation of the standard TCP/IP networking protocol stack in SML (75 parseable files, 8545 lines of code)\footnote{\url{ftp://ftp.cs.cmu.edu/project/fox/snapshot/foxnet.tar.gz}}
\item Til, a type-directed compiler for ML (618 parseable files, totalling 222317 lines of code)\footnote{\url{http://www.cs.cornell.edu/Info/People/jgm/til.tar.Z}}
\item MLton, an open-source, whole-program, optimizing SML compiler (855 parseable files, 168323 lines of code)\footnote{\url{http://sourceforge.net/projects/mlton/files/mlton/20130715/mlton-20130715.src.tgz/download}}
\end{enumerate}

The layout of this paper is as follow.
Section~\ref{sec:metric} provides a brief background
concerning software metrics and source code analysis.
We look at how well expert code conforms to readily available
style guides in section~\ref{sec:style}.
Section~\ref{sec:syntax} discusses an analysis
of the distribution of syntactic forms.
The implementation is discussed
in section~\ref{sec:impl}. Finally, we conclude and reflect in section~\ref{sec:future}.
\section{SOFTWARE METRICS AND SOURCE CODE ANALYSIS}\label{sec:metric}
\subsection{SOFTWARE METRICS}
One way to tackle the challenges and complexities of software development is to employ
\emph{software metrics}. These metrics allow developers and their managers to make
measurements about cost and effort, productivity, assessment of reliability and
quality, evaluating processes (including development and maintenance), and elements
related to project and product management.\cite{Ord08} Despite being around since
the early 1970s, there are still some significant issues with how measurements
about software are made in practice and serious criticisms about whether or not the metrics
measure anything useful (see for example \cite{Jon94} and \cite{Bou12}).
Nevertheless, due to the high potential of prudent measurements,
a growing number of organizations have integrated software measurement programs into
their workflows.\cite{Ord08}

For our project, the whole of software metrics is too monolithic to employ on
such a small-scale project. Therefore, we aim to look at a more specific set of measurements,
mostly dealing with style. This approach has been used for C++\cite{Aye98} and C\cite{Tak11}.
\subsection{SOURCE CODE ANALYSIS}
\cite{Bin07} provides a definition:
\begin{quote}
\emph{Source code analysis} is the process of extracting
information about a program from its source code
or artifacts (e.g., from Java byte code or execution
traces) generated from the source code using automatic tools.
\emph{Source code} is any static, textual,
human readable, fully executable description of
a computer program that can be compiled automatically into an executable form.
\end{quote}

According to \cite{Bin07}, source code analysis has three components: a parser,
the internal representation, and the analysis of this representation.
Internal representations are many and varied, including abstract syntax trees,
control-flow graphs, and call graphs.

Source code analysis has a variety of applications in such areas as
automotive software engineering, debugging, fault location, software maintenance,
etc.\cite{Bin07}

We use the parser of the Standard ML of New Jersey compiler along with the accompanying
abstract syntax tree that it produces to perform our analyses. Our analysis
consists of static analyses of the abstract syntax tree, looking for
syntactic constructs and patterns in usage.
\section{STYLE}\label{sec:style}
\subsection{Style Guides}\label{subsec:guide}
If we wish to examine how well expert code conforms to style, we need to decide
what good style is. A quick search of the web found a few style guides, from which
we will distill a few points of style to examine in the expert code:
\begin{enumerate}
\item CS312 SML Style Guide, from Cornell\footnote{\url{http://www.cs.cornell.edu/courses/cs312/2008sp/handouts/style.htm}}
\item SML Style Guide, from CMU\footnote{\url{http://www.cs.cmu.edu/~15150/resources/style.pdf}}
\item Syntactic Conventions, from MLton website\footnote{\url{http://mlton.org/SyntacticConventions}}
\end{enumerate}
Let's take a look at what we can discover.
\subsection{Tabs vs. Spaces}\label{subsec:tab}
If one wishes to start a flame war on StackOverflow, one simply needs to start
a debate over spaces and tabs. The three style guides, nevertheless, are
united on the view that tabs are taboo in SML code. To paraphrase the CMU
style guide, white space should emphasize the structure of the code.\cite{Cmu12}
Tabs, which are potentially rendered differently for
different users, cannot be used to consistently provide the desired indentation.
For some users, this ability to customize the size of tabs is an asset not
a drawback.

We can see from Table~\ref{table:whitespace} that most expert code definitely does
not conform to the tab/spaces rule -- we see a tab character approximately once every third line.
It seems that the coders made a decision to use tabs and stuck to the decision fairly well.
The notable exception is complete lack of tabs in MLton, whose style guide we are using as an example.
It's good to see that the principled experts at MLton stick to their own guidelines.
But based on the fiery nature of the debate over the proper character
for indenting, perhaps it is not surprising that the tab/spaces
rule from style guides is adopted by only a select group of coders.
While we can't say that the experts choose one style over the other in accordance with
any style guide, we can say that the experts are at least consistent, which is
a potentially helpful observation we can pass on to beginner coders.
\subsection{The 80-Column Rule}\label{subsec:80}
All three style guides recommend a line of code should not exceed 80 columns.
The 80-column rule is a UNIX convention and many text editors automatically
wrap at 80 columns. \cite{Cmu12}

\begin{table}[t!]
\centering
\begin{tabular}{|l||c|c||c|c|}
\hline
Project & Tab violations & Lines per instance & Column violations & Lines per instance \\ \hline\hline
SML/NJ & 23115 & 3.5096 & 350 & 231.78 \\
MLKit & 184554 & 2.8736 & 18170 & 29.187 \\
FoxNet & 2861 & 2.9867 & 31 & 275.65 \\
Til & 78494 & 2.8323 & 1380 & 161.10 \\
MLton & 0 & -- & 2884 & 58.364 \\ \hline
\end{tabular}
\caption{Style violations involving whitespace}
\label{table:whitespace}
\end{table}

The example code from the expert ML users we looked at clearly cannot
resist violating the 80-column rule (Table~\ref{table:whitespace}), with
those for MLKit being particularly egregious. A quick glance
at the violations shows that most of the cases consist of exceeing the limit
by only a few characters. While most editors can be configured to insert
spaces in place of tabs, there is no active check on enforcing the 80-column
rule while coders are working.
Indeed, MLton contains many width violations in spite of what is stated in the style guide.
Since the level of indentation does more to highlight the structure of code than
limiting the width of text does, it is perhaps not surprising that more
emphasis was placed on eliminating tabs than on observing the 80-column rule.
\subsection{Verbosity in \texttt{if} Expressions}
A convention cited in the Cornell style guide is that we should use \texttt{if}
expressions wisely. There are two specific uses of \texttt{if} that we
chose as violations.
\begin{enumerate}
\item Either one or both of the branches are boolean literals. We can rewrite the if expression with judicious use of \texttt{not}, \texttt{orelse}, and \texttt{andalso}
\item The test consists of \texttt{not} applied to another literal. We should just swap the two branches of the conditional.
\end{enumerate}
Rewriting these cases should help to improve readability and reduce verbosity in the code.

Table~\ref{table:style} shows the frequency of \texttt{if} violations in the five projects we selected.
There do not seem to be many violations -- on average approximately one every couple of thousand lines --
but they do still occur.
On inspection, the violations tend to fall into two groups: most are
missed opportunities to rewrite the \texttt{if} statement in potentially simpler way; 
a few are made up of complicated \texttt{if} expressions where rewriting may not improve readability at all.
The first example below shows a \texttt{if} expression that could be rewritten as \texttt{e = t orelse f r}.
In the second case, the use of \texttt{orelse} does not significantly improve the readability or conciseness
of the expression. The problem is that the \texttt{if} expression has the same value as the test expression,
but if it evaluates to \texttt{false}, we also wish to evaluate some code for side-effects.

\begin{figure}[h!]
\begin{enumerate}
\item \texttt{if e = t then true else f r}
\item \texttt{if ar1 = ar2 then true else (}$\langle$\emph{code with side-effects}$\rangle$\texttt{; false)}
\end{enumerate}
\caption{Two \texttt{if} expressions from expert code where the \texttt{then} branch is the value \texttt{true}. In example 1, we could
rewrite in a more concise way by using \texttt{orelse}. In example 2, the use of \texttt{orelse} does not help much.}
\label{figure:ifthentrue}
\end{figure}

The expert code contains many uses of \texttt{orelse} and \texttt{andalso}, so we are forced to
conclude that the coders either missed an opportunity to use those syntactic constructs or chose
not to do so. But when we see in SML/NJ, MLKit, and Til an expression of the form:
\[\texttt{if }\langle expression\rangle\texttt{ then true else false}\]
we cannot help but wonder if it not just the former scenario. Despite the existence of
our selected \texttt{if} violations in expert code, we
recommend that beginners avoid verbosity in their \texttt{if} expressions by writing them
in more concise forms.

\begin{table}[h!]
\centering
\begin{tabular}{|l||c|c||>{\centering\arraybackslash\hspace{0pt}}p{1in}|c|}\hline
Project & \texttt{if} violations & Lines per instance & Missed fold opportunities & Lines per instance \\ \hline\hline
SML/NJ & 25 & 3245.0 & 75 & 1081.7 \\
MLKit & 182 & 2913.9 & 1470 & 360.77 \\
FoxNet & 0 & -- & 10 & 854.50 \\
Til & 149 & 1492.1 & 751 & 296.03 \\
MLton & 72 & 2337.8 & 202 & 833.28 \\ \hline
\end{tabular}
\caption{Selected usage style violations (see text)}
\label{table:style}
\end{table}

\subsection{Fold}\label{subsec:fold}
The Cornell and CMU style guides both suggest making heaving use of library functions.
The author has noted in discussions with the course staff for a programming languages course
that library functions for lists were frequent missed opportunities. We
chose to look at the \texttt{List} structure from the basis. Since many of the functions
from this structure, for example, \texttt{map}, \texttt{exists}, \texttt{all}, \texttt{filter},
and \texttt{rev}, can be written in terms of a fold over a list, we decided to look
for missed opportunities to apply a fold. \cite{Jeu13} describes an algorithm for turning
explicitly recursive functions into folds. We chose not to tackle the more challenging
problem of finding all fold opportunities or transforming them,
but instead chose to look for a specific subset where folds might be applied.

Like \cite{Jeu13}, we are looking for cases of explicit recursion. Specifically, we try find
find instances of the following form:
\begin{center}
\texttt{fun f }\(e_{1}\ldots e_{i-1}\)\texttt{ (x::xs) }\(e_{i+1}\ldots e_{n}\) \(= e\)

where $e$ has the subexpression \texttt{f }\(v_{1}\ldots v_{i-1}\)\texttt{ xs }\(v_{i+1}\ldots v_{n}\)
\end{center}
That is, we're explicitly calling a recursive function on the tail of a input list.
The only other restriction is that the only list literal we allow in the same position
a declared pattern is the empty list literal (\texttt{[]}). This prevents idiosyncratic
behavior from being introduced into an otherwise sound definition by structural induction.
We won't concern ourselves with the order of the pattern match because either the patterns
are mutually exclusive (e.g., \texttt{[]} or a cons cell) or there is a redundant match
and the compiler will throw an error.

\begin{figure}[h!]
\begin{enumerate}
\item \begin{verbatim}
fun procstrbs([]) = []
  | procstrbs((A.STRB{name,...})::rest) = name::(procstrbs rest)
\end{verbatim}

rewrite as:
\begin{verbatim}
fun procstrbs = List.foldr (fn (A.STRB{name,...}, a) => name :: a) []
\end{verbatim}
\item \begin{verbatim}
fun find (h :: t) = if h=index_n2 then true else find t
  | find nil =  false
\end{verbatim}

rewrite as:
\begin{verbatim}
fun find = List.exists (fn x => x = index_n2)
\end{verbatim}
\item \begin{verbatim}
fun find [] = raise NotFound
  | find ((tv',ty)::rest) = if eqTyvar(tv,tv') then ty
                            else find rest
\end{verbatim}

rewrite as:
\begin{verbatim}
fun find = List.foldl
             (fn ((tv',ty),f) => if eqTyvar(tv,tv') then ty else f tv)
             (fn _ => raise NotFound)
\end{verbatim}
\end{enumerate}
\caption{Rewriting explicit recursion with library functions}
\label{figure:fold}
\end{figure}

We see from Table~\ref{table:style} that missed opportunities for fold occur more often
than opportunities to rewrite \texttt{if} expressions. Perhaps this is
because \texttt{if} statements are relatively easy to reason about, but
rewriting a function as a fold over a list can be much more challenging.
And when a fold is not obvious, the programmer is surely tempted to just
get the job done with a recursive function definition.

Few fold opportunities were very obvious, for example, Figure~\ref{figure:fold} example 1.
Indeed, we did not find many fold opportunities of this variety.

Sometimes, the recursive function can be rewritten in terms of another library function
from the \texttt{List} structure, which itself could be written as fold.
Figure~\ref{figure:fold} example 2 shows an example that can be rewritten with \texttt{find}.

The transformation to a fold can be particularly challenging when the recursive function
has an accumulating parameter, but as \cite{Jeu13} points out,
when we consider the function as returning a function that takes a parameter
instead of having an accumulating parameter, the transformation to a fold
can be easier. An example of this type is shown in Figure~\ref{figure:fold} example 3.
Many recursive functions with side-effects can be rewritten in this manner.

The fact that a small fraction of the missed fold opportunities were obvious
suggests that the expert coders were actively trying to rewrite their
recursive functions using folds or other library functions on lists. The
cases where they did not convert such explicit recursion into folds
were either missed or perhaps left in their recursive form for other
reason of legibility.
\subsection{Final thoughts on style}\label{subsec:stylethoughts}
We conclude this section with a few thoughts on style.
The takeaway for beginners from this section should not be
that because we see style violations in expert code,
style is not important. On the contrary, we believe that
these errors reflect the challenges that even experts
struggle with in the code, both in identifying places
whether style violations occur and finding consensus on
what good style is. Our suggestion to the beginners is
remember style's purpose of making code easier to read
and maintain, and then being as consistent as possible
in applying the style of his or her choice.
\section{SYNTACTIC FORMS}\label{sec:syntax}
\subsection{Imperative Features}\label{subsec:imper}
In Prof. Norman Ramsey's class on programming languages, one easy way to lose points
on any assignment was the unnecessary use \emph{imperative} language features when programming in a \emph{functional} language.
\footnote{See, for example: \url{http://www.cs.tufts.edu/comp/105-2013s/homework/scheme.html}, specifically, the section titled ``Dire Warnings''}
In Standard ML, there are two main imperative constructs in terms of expressions:
(1)~the \texttt{while} expression and (2)~a list of expression separated by semicolons (similar to the \texttt{begin...end} syntax of Pascal)\cite{Ull98}.
The former has the form \texttt{while <boolean-expression> do <expression>} and always returns a value of unit type.
The return value indicates that the \texttt{while} expression's purpose is to produce the side-effects associated
with the expression in its body. The sequence of expressions evaluates only to the last in that sequence, indicating
in a similar fashion, that all expressions in the list except for the last are evaluated for side-effects.

Of course, one of the paradigms in writing functional programs is to avoid side-effects.
Such a principled approach allows us to reason better about correctness and
removes the constraints imposed by having a fixed order of execution.\cite{Hug90} Therefore,
it behooves us to examine whether such imperative features are necessary or avoidable.
\subsubsection{Expressions with \texttt{while}}
\begin{table}[h!]
\centering
\begin{tabular}{|l||c|c||c|c|}
\hline
Project & \multicolumn{2}{c||}{Instances of \texttt{while}} & \multicolumn{2}{c|}{Lines per instance} \\ \cline{2-3}\cline{4-5}
 & total & outside of tests & total & outside of tests \\ \hline\hline
SML/NJ & 0 & 0 & -- & --\\ 
MLKit & 18 & 0 & 29463 & --\\
FoxNet & 0 & 0 & -- & -- \\
Til & 104 & 2 & 2137.66 & 11158.5 \\
MLton & 20 & 0 & 8416.15 & --\\ \hline
\end{tabular}
\caption{Occurrences of \texttt{while} expressions}
\label{table:while}
\end{table}
As we can see from Table~\ref{table:while}, two of the projects -- SML/NJ and FoxNet -- contain no occurrences
of \texttt{while} loops at all.

MLKit contains a few handfuls of \texttt{while} usages, but these instances
occur in regression tests for the \texttt{Word8Array} structure and not in the actual implementation of the compiler.
The 20 occurrences of \texttt{while} expressions in MLton are likewise found in code for regression testing but
also in MLton's benchmarks suite.

Of the 104 instances of a \texttt{while} expression in the Til project,
only 2 of these were found outside of a source file used for regression or benchmark testing.
In both instances, the body of the while loop includes modifying a mutable reference, which justifies the use of
an imperative feature. Getting rid of the while loops requires a design of how the code works so
that we no longer need to keep track of mutable state and thus, is not very straightforward.

Overall, we can observe that there are very few usages of \texttt{while} expressions
in expert projects (on average, one occurrence per about 2000 lines of code).
When code used for testing is excluded from the analysis, we found only one use
of a \texttt{while} expression which was used to modify mutable data.
From the analysis, expert ML programmers seemed quite principled in avoiding imperative
elements of ML. This is perhaps not surprising since they could have chosen
to implement in any language but selected a functional language in the end.
We therefore recommend that beginners avoid using \texttt{while} loops completely.
\subsubsection{Expression Lists}
\begin{table}[h!]
\centering
\begin{tabular}{|l||c|c|}
\hline
Project & Instances of expression lists & Lines per instance \\ \hline\hline
SML/NJ & 1970 & 41.18 \\ 
MLKit & 7900 & 67.13 \\
FoxNet & 77 & 111.0 \\
Til & 4414 & 50.37 \\
MLton & 1907 & 88.27 \\ \hline
\end{tabular}
\caption{Occurrences of expressions lists}
\label{table:explist}
\end{table}
Table~\ref{table:explist} shows how often expression lists are used in our
examples of expert ML code. We find that the number of uses is significantly
greater than that of the \texttt{while} expression. The greatest number
of occurrences, normalized by the number of lines, appears to be in the SML/NJ
compiler where we find an expression list on average once every with every
40 or so lines of code.

The expression lists are likely used for the side-effects of the non-terminal
expression in the list. Sadly, the expressions are quite complex and difficult
to aggregate into meaningful groupings programmatically. Nevertheless,
looking at the examples of expression lists in the expert code, we find that
the expression lists frequently occur in the following contexts:
\begin{itemize}
\item[$\bullet$] pretty printing
\item[$\bullet$] outputting error messages
\item[$\bullet$] other types of I/O
\item[$\bullet$] assignment of reference variables (with \texttt{:=})
\item[$\bullet$] arrays
\item[$\bullet$] with the keyword \texttt{use} or the compilation manager to bring in other modules
\end{itemize}

Haskell has the IO monad to allow users to perform I/O in a purely functional way. \cite{Jon93}
Standard ML does not, so users are left to perform their
I/O unsafely in imperative fashion.

Arrays and references are two examples that \cite{Ull98} cites as way to ``violate the functional,
side-effect-free style,'' but also noting that ``there are situations where programs cannot
be made adequately efficient unless we are allowed to change some value bindings.''

Imperative features are clearly unavoidable as evidenced in expert ML code. The experts do
limit their uses of expression lists to a few general cases, mostly dominated by I/O.
We conclude that the ML experts believe in the ``functional, side-effect-free'' style
and conform to it as much as possible. Beginners in ML are encouraged for follow their example.
\subsection{List Library Functions}\label{subsec:imp}
We wanted to see if there was any discernable pattern in how expert programmers
used library functions, but not all projects require the same library.
It is difficult to imagine writing a substantial amount of code in ML without
relying heavily on lists, so we decided to just examine how expert programmer relied upon the functions
in the \texttt{List} structure from the standard basis.

\begin{table}[h!]
\centering
\begin{tabular}{|l||>{\centering\arraybackslash}p{0.62in}|>{\centering\arraybackslash\hspace{0pt}}p{0.9in}|>{\centering\arraybackslash\hspace{0pt}}p{0.6in}|>{\centering\arraybackslash\hspace{0pt}}p{0.5in}|>{\centering\arraybackslash\hspace{0pt}}p{0.6in}|}
\hline
Function & SML/NJ & MLKit & Foxnet & Til & MLton \\ \hline\hline
\texttt{::} & 882 & 10250 & 97 & 2496 & 1585 \\
\texttt{@} & \textbf{205} & \textbf{1040} & \textbf{18} & \textbf{476} & \textbf{241} \\
\texttt{all} & 13 & 458 & 0 & 63 & 95 \\
\texttt{app} & \textbf{331} & \textbf{1236} & 3 & \textbf{434} & \textbf{231} \\
\texttt{drop} & 0 & 130 & 0 & 7 & 20 \\
\texttt{exists} & 24 &  598 & 0 & \textbf{542} & 152 \\
\texttt{filter} & 17 & 236 & 3 & 62 & 45 \\
\texttt{find} & 48 & 258 & 0 & 64 & 48 \\
folds (\texttt{foldl},\texttt{foldr}) & \textbf{237} (89,\textbf{148}) & \textbf{1220} (680,540) & \textbf{15} (7,8) & 75 (61,14) & 205 (129,76) \\
\texttt{getItem} & 0 & 64 & 0 & 0 & 5 \\
\texttt{hd} & 42 & 130 & 0 & \textbf{413} & 59 \\
\texttt{last} & 8 & 116 & 0 & 198 & 48 \\
\texttt{length} & \textbf{163} & \textbf{1188} & 3 & \textbf{429} & \textbf{340} \\
\texttt{map} & \textbf{701} & \textbf{3314} & \textbf{61} & \textbf{1642} & \textbf{521} \\
\texttt{mapPartial} & 7 & 32 & 0 & 0 & 10 \\
\texttt{nth} & 5 & 74 & 0 & 32 & 21 \\
\texttt{null} & 8 & 120 & 0 & 23  & 64 \\
\texttt{partition} & 14  & 50 & 0 & 3 & 11 \\
\texttt{rev} & 137 & 754 & \textbf{13} & 334 & \textbf{272} \\
\texttt{revAppend} & 1 & 8 & 0 & 0 & 4 \\
\texttt{tabulate} & 1 & 206 & 0 & 24  & 100 \\
\texttt{take} & 6 & 130 & 0 & 10 & 23 \\
\texttt{tl} & 54 & 200 & 0 & \textbf{505} & 63 \\\hline\hline
Total & 2904 & 21812 & 213 & 7832 & 4163 \\
Lines per call & 27.935 & 24.314 & 40.117 & 28.386 & 40.433 \\\hline
\end{tabular}
\caption{Calls to functions from the \texttt{List} structure (\texttt{concat} omitted). Bolded entries each account for more than 5\% of the total number of occurrences.}
\label{table:list}
\end{table}

Before we analyze the data, we should highlight some salient points.
Since the easiest way to create lists of arbitrary size is to the use the cons operator (\texttt{::}),
this operator naturally occurs the most, accounting for, in some cases, up to almost half
the occurrences of function calls. But we don't gain much insight from looking at this operator
because it is so common and critical to working with lists. It should also be noted
that we are excluding any occurrences of the cons operator used in pattern matching.
Additionally, we had trouble distinguishing \texttt{concat} using from the \texttt{List} structure
as opposed to the \texttt{String} structure. As a result, the occurrences of \texttt{concat} have been omitted.
Our results are tabulated in Table~\ref{table:list}.

It is amazing that list functions are used with almost the same frequency (normalized
by the number of lines) in every expert project. The normalized frequency
basically stay constant, relative to each other, even when we exclude the occurrences of the cons operator.

The values in bold indicate that a function accounts for more than 5\% of all function calls to the \texttt{List} structure.
We see that list concatenation (\texttt{@}) and \texttt{map} break the threshold in all 5 projects. Between the
two, \texttt{map} is more common, occurring almost as frequency as the cons operator in some cases. This
suggests possibly that expert coders in ML are transforming data in bulk within a list container.

Other functions of note are \texttt{length} and \texttt{app}, both of which each account for more than 5\% of
occurrences in four of five projects. The \texttt{app} is particularly interesting because it can be
considered an imperative version of \texttt{map}, which we have observed is called quite often. We hypothesize
that not only do programmer transform data in bulk as a list with \texttt{map}, the execute side-effects
in bulk in a list with \texttt{app}. The \texttt{length} function's popularity suggests that
the cardinality of a list is often more important than its contents.

The pair of fold functions, taken together, break the threshold on three of five projects.
This is perhaps not surprising since a fold is an excellent way to aggregrate data in a list
into another value, possibly even another list. Indeed, many of the functions on lists
including \texttt{map} and \texttt{length} could be rewritten using a fold.

Finally, we point out that the Til project makes heavy use of the head (\texttt{hd}) and tail (\texttt{tl})
functions which respectively return the first element and all but the first element in a list.
That no other project makes heavy use of these two functions is interesting because from
the author's experience, extracting the head and tail of a list is a frequent necessity.
It is likely that the other four projects make heavy use of pattern matching on a cons cell (e.g., \texttt{x :: xs})
instead of expliciting call either \texttt{hd} or \texttt{tl}.

To conclude this section, we recommend to beginners to make heavy use of library functions
for lists. The experts particularly seem to like the list mapping and list contentation operators.
And despite our criticism of missed fold opportunities, folds are also quite common in code.
Based on a preference by coders on four of five projects, we recommend using pattern
matching to extract the head and tail of a list instead of explicit function calls.
\subsection{Program Hierarchy and Layout}\label{subsec:struct}
\subsubsection{Modularity}\label{subsubsec:modularity}
\subsubsection{Helper Functions in \texttt{Let} Expressions}\label{subsubsec:let}
\section{IMPLEMENTATION}\label{sec:impl}
\section{CONCLUSIONS AND FUTURE WORK}\label{sec:future}
\begin{thebibliography}{99}
\bibitem[Ayerbe and Vazquez 1998]{Aye98} Ayerbe, A., Vazquez, I. (1998) Software Products Quality Improvement with a Programming Style Guide and a Measurement Process. In \emph{Proceedings 22nd Annual International Computer Software and Applications Conference (COMPSAC'98)}. 172--178.
\bibitem[Binkley 2007]{Bin07} Binkley, D., 2007. Source Code Analysis: A Road Map. In \emph{Workshop on the Future of Software Engineering (FOSE'07)}. Minneapolis, MN. 104--119. Washington, D.C.: IEEE Computer Society.
\bibitem[Bouwers et al. 2012]{Bou12} Bouwers, E., Visser, J., van Deursen, A. (2012) Getting what you measure. \emph{Commun. ACM}, \textbf{55}, 54--59.
\bibitem[CMU 2012]{Cmu12} CMU Computer Science Department. (2012) SML Style Guide. Accessed on 14 Nov 2013 from \url{http://www.cs.cmu.edu/~15150/resources/style.pdf}
\bibitem[Gladwell 2008]{Gla08} Gladwell, M. (2008) \emph{Outliers}. Little, Brown and Co., New York, NY.
\bibitem[Hughes 1990]{Hug90} Hughes, J. (1990) Why Functional Programming Matters. In D.\,A.\,Turner, ed, \emph{Research Topics in Functional Programming}. Boston, MA: Addison Wesley.
\bibitem[Jones 1994]{Jon94} Jones, C. (1994) Software metrics: good, bad and missing. \emph{Computers}, \textbf{27}, 98--100.
\bibitem[Ordonez and Hadda 2008]{Ord08} Ordonez, M.\,J. Hadda, H.\,M. (2008) The State of Metrics in Software Industry. In \emph{5th International Conference Information Technology: New Generations (ITNG'08)} Las Vegas, NV. 453--458. Washington, D.C.: IEEE Computer Society.
\bibitem[Peyton Jones, Wadler 1993]{Jon93} Peyton Jones, S.\,L., Wadler, P. (1993) Imperative Functional Programming. In \emph{ACM Symposium on Principles of Programming Languages (POPL'93)}. Charleston, SC. 71--84. New York, NY: ACM.
\bibitem[Takai et al. 2011]{Tak11} Takai, Y., Kobayashi, T., Agusa, K. (2011) Software Metrics Based on Coding Standards Violations. In \emph{2011 Joint Conference of the 21st Int'l Workshop on Software Measurement and 6th Int'l Conference on Software Process and Product Measurement (IWSM-MENSURA)} Nara, Japan. 273--278. Washington, D.C.: IEEE Computer Society.
\bibitem[Ullman 1998]{Ull98} Ullman, J.\,D. (1998) \emph{Elements of ML Programming} (ML97 Ed). Prentice Hall, Upper Saddle River, NJ.
\bibitem[Van der Jeugt et al. 2013]{Jeu13} Van der Jeugt, J., Keuchel, S., Schrijvers, T. (2013) Bringing Functions into the Fold. Unpublished manuscript.
\bibitem[Vogelsang et al. 2010]{Vog10} Vogelsang, S., Fehnker, A., Huuck, R., Reif, W. (2010) Software Metrics in Static Program Analysis. In \emph{Formal Methods and Software Engineering. Proceedings 12th International Conference on Formal Engineering Methods (ICFEM'10)}. Shanghai, China. 485--500. Heidelberg, Germany: Springer.
\end{thebibliography}
\end{document}
